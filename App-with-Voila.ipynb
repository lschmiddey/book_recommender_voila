{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasses Buchempfehlungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was würde Lasse zu diesem Buch sagen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nimm ein Bild von einer Seite im Buch auf, lade es hier hoch und du wirst erfahren, wie gut Lasse dieses Buch finden würde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/envs/fastai/lib/python3.8/site-packages (3.2.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/fastai/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/fastai/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/envs/fastai/lib/python3.8/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/fastai/lib/python3.8/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from transformers) (4.48.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/fastai/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from transformers) (2020.7.14)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from transformers) (0.1.86)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from transformers) (0.8.1rc2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from requests->transformers) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: six in /opt/conda/envs/fastai/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /opt/conda/envs/fastai/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/fastai/lib/python3.8/site-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: pytesseract in /opt/conda/envs/fastai/lib/python3.8/site-packages (0.3.6)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/fastai/lib/python3.8/site-packages (from pytesseract) (7.2.0)\n",
      "Requirement already satisfied: voila in /opt/conda/envs/fastai/lib/python3.8/site-packages (0.2.3)\n",
      "Requirement already satisfied: nbconvert<7,>=6.0.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from voila) (6.0.6)\n",
      "Requirement already satisfied: jupyter-server<2.0.0,>=0.3.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from voila) (1.0.1)\n",
      "Requirement already satisfied: jupyter-client<7,>=6.1.3 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from voila) (6.1.6)\n",
      "Requirement already satisfied: nbclient<0.6,>=0.4.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from voila) (0.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (2.6.1)\n",
      "Requirement already satisfied: jinja2>=2.4 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (2.11.2)\n",
      "Requirement already satisfied: testpath in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (0.4.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (0.1.1)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (4.6.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (0.3)\n",
      "Requirement already satisfied: nbformat>=4.4 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (5.0.7)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (4.3.3)\n",
      "Requirement already satisfied: bleach in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (3.1.5)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (1.4.2)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbconvert<7,>=6.0.0->voila) (0.6.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (19.0.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (0.8.3)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (0.2.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (0.8.0)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (1.5.0)\n",
      "Requirement already satisfied: tornado>=5.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-server<2.0.0,>=0.3.0->voila) (6.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jupyter-client<7,>=6.1.3->voila) (2.8.1)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbclient<0.6,>=0.4.0->voila) (1.4.0)\n",
      "Requirement already satisfied: async-generator in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbclient<0.6,>=0.4.0->voila) (1.10)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jinja2>=2.4->nbconvert<7,>=6.0.0->voila) (1.1.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert<7,>=6.0.0->voila) (3.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/fastai/lib/python3.8/site-packages (from traitlets>=4.2->nbconvert<7,>=6.0.0->voila) (1.15.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/fastai/lib/python3.8/site-packages (from traitlets>=4.2->nbconvert<7,>=6.0.0->voila) (4.4.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/fastai/lib/python3.8/site-packages (from bleach->nbconvert<7,>=6.0.0->voila) (20.4)\n",
      "Requirement already satisfied: webencodings in /opt/conda/envs/fastai/lib/python3.8/site-packages (from bleach->nbconvert<7,>=6.0.0->voila) (0.5.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert<7,>=6.0.0->voila) (49.6.0.post20200814)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert<7,>=6.0.0->voila) (0.16.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert<7,>=6.0.0->voila) (20.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from packaging->bleach->nbconvert<7,>=6.0.0->voila) (2.4.7)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/fastai/bin/jupyter\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/conda/envs/fastai/lib/python3.8/site-packages/jupyter_core/command.py\", line 247, in main\n",
      "    command = _jupyter_abspath(subcommand)\n",
      "  File \"/opt/conda/envs/fastai/lib/python3.8/site-packages/jupyter_core/command.py\", line 133, in _jupyter_abspath\n",
      "    raise Exception(\n",
      "Exception: Jupyter command `jupyter-serverextensions` not found.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install pytesseract\n",
    "!pip install voila\n",
    "!jupyter serverextensions enable voila --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ign:1 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  InRelease\n",
      "Hit:2 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release\n",
      "Get:4 http://security.ubuntu.com/ubuntu xenial-security InRelease [109 kB] \n",
      "Ign:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease\n",
      "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release\n",
      "Hit:8 http://archive.ubuntu.com/ubuntu xenial InRelease                        \n",
      "Hit:9 http://archive.ubuntu.com/ubuntu xenial-updates InRelease\n",
      "Hit:10 http://archive.ubuntu.com/ubuntu xenial-backports InRelease\n",
      "Fetched 109 kB in 0s (210 kB/s)                   \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libleptonica-dev is already the newest version (1.73-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "tesseract-ocr is already the newest version (3.04.01-4).\n",
      "tesseract-ocr-dev is already the newest version (3.04.01-4).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libtesseract-dev is already the newest version (3.04.01-4).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "tesseract-ocr-deu is already the newest version (3.04.00-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install libleptonica-dev -y\n",
    "!apt-get install tesseract-ocr tesseract-ocr-dev -y\n",
    "!apt-get install libtesseract-dev -y\n",
    "!apt-get install tesseract-ocr-deu  #for deutsch (German)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "from PIL import Image, ImageFilter \n",
    "import pytesseract\n",
    "import re\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from pathlib import Path\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_img(input_img):\n",
    "    \n",
    "    img = input_img.rotate(angle=270, resample=0, expand=10, center=None, translate=None, fillcolor=None)\n",
    "    img = img.filter(ImageFilter.MedianFilter)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(img):\n",
    "    return pytesseract.image_to_string(img, lang=\"deu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_pattern(text):\n",
    "    return pattern.sub(lambda m: rep[re.escape(m.group(0))], text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = {\"\\n\": \"\", \"`\": \"\", '%':\"\", '°': '', '&':'', '‘':'', '€':'e', '®':'', '\\\\': '', '5':'s', '1':'i', '_':'', '-':''} # define desired replacements here\n",
    "\n",
    "# use these three lines to do the replacement\n",
    "rep = dict((re.escape(k), v) for k, v in rep.items()) \n",
    "#Python 3 renamed dict.iteritems to dict.items so use rep.items() for latest versions\n",
    "pattern = re.compile(\"|\".join(rep.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "def tokenize_text(sent):\n",
    "    \n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        truncation=True,\n",
    "                        max_length = 256,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        #padding='longest',\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    \n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(text):\n",
    "    \n",
    "    input_ids, attention_masks = tokenize_text(text)\n",
    "    dataset = TensorDataset(input_ids, attention_masks)\n",
    "    batch_size = 1\n",
    "    app_dataloader = DataLoader(\n",
    "                dataset, # The validation samples.\n",
    "                batch_size = batch_size # Evaluate with this batch size.\n",
    "            )\n",
    "    return app_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataloader):\n",
    "    # Prediction on test set\n",
    "    device = torch.device('cpu')\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    predictions = []\n",
    "\n",
    "    # Predict \n",
    "    for batch in dataloader:\n",
    "\n",
    "            # Add batch to CPU\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Unpack the inputs from our dataloader\n",
    "            b_input_ids, b_input_mask = batch\n",
    "\n",
    "            # Telling the model not to compute or store gradients, saving memory and \n",
    "            # speeding up prediction\n",
    "            with torch.no_grad():\n",
    "              # Forward pass, calculate logit predictions\n",
    "              outputs = model(b_input_ids, token_type_ids=None, \n",
    "                              attention_mask=b_input_mask)\n",
    "\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "\n",
    "            # Store predictions and true labels\n",
    "            predictions.append(logits)\n",
    "            \n",
    "            return np.argmax(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-german-cased'\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', PRE_TRAINED_MODEL_NAME)    # Download vocabulary from S3 and cache.\n",
    "n_classes=5\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-german-cased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = n_classes, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model.load_state_dict(torch.load(p/'model_5epochs_lr1e-4.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_upload = widgets.FileUpload()\n",
    "out_pl = widgets.Output()\n",
    "rating_widget = widgets.Label()\n",
    "btn_run = widgets.Button(description='Lasses Empfehlung:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_text(change):\n",
    "    img = PILImage.create(btn_upload.data[-1])\n",
    "    out_pl.clear_output()\n",
    "    with out_pl: display(proc_img(img).to_thumb(256,256))\n",
    "    text = use_pattern(get_text(proc_img(img)))\n",
    "    star_rating = predict(create_dataloader(text))\n",
    "    rating_widget.value = f'Lasse würde diesem Buch {star_rating+1} Stern(e) von 5 Sternen geben!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_run.on_click(on_click_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86fff91c0fe481e8c596a9f308d1550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Upload Bild von Buchseite'), FileUpload(value={}, description='Upload'), Button(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VBox([widgets.Label('Upload Bild von Buchseite'),\n",
    "     btn_upload, btn_run, out_pl, rating_widget])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
